{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import model.aotgan \n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from loss1 import loss as loss_module\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'rates':[1, 2, 4, 8],\n",
    "        'block_num':8,\n",
    "        'model':'aotgan',\n",
    "        'gan_type':\"smgan\",\n",
    "        'lrg':1e-4,\n",
    "        'lrd':1e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':8,\n",
    "        'epochs':500,\n",
    "        'data_path':'../../data/dataset/colon/',\n",
    "        'num_workers':4,\n",
    "        'rec_loss':'1*L1+250*Style+0.1*Perceptual'\n",
    "        }\n",
    "losses = list(params['rec_loss'].split(\"+\"))\n",
    "params['rec_loss'] = {}\n",
    "for l in losses:\n",
    "    weight, name = l.split(\"*\")\n",
    "    params['rec_loss'][name] = float(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, args,dataset):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.w = self.h = args['image_size']\n",
    "\n",
    "        # image and mask\n",
    "        self.image_path =glob(args['data_path']+dataset+'/image/*.png')\n",
    "        self.mask_path = [i.replace('/image','/mask') for i in self.image_path]\n",
    "        self.trans_1 = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((args['image_size'],args['image_size']), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "            ]\n",
    "        )\n",
    "    def trans(self,image_t,a):\n",
    "        image_t=F.to_tensor(F.rotate(self.trans_1(image_t),a))\n",
    "        return image_t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        image = Image.open(self.image_path[index]).convert(\"RGB\")\n",
    "        filename = os.path.basename(self.image_path[index])\n",
    "        mask = Image.open(self.mask_path[index])\n",
    "        mask = mask.convert(\"L\")\n",
    "        # augment\n",
    "        angle=random.randint(0, 360)\n",
    "        \n",
    "        image = F.to_tensor(self.trans_1(image)) * 2.0 - 1.0\n",
    "        mask =F.to_tensor(self.trans_1(mask))\n",
    "        \n",
    "        return image, mask, filename\n",
    "    \n",
    "test_dataset=CustomDataset(params,'test')\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG =model.aotgan.InpaintGenerator(params).to(device)\n",
    "optimG = torch.optim.Adam(netG.parameters(), lr=params['lrg'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "netD = model.aotgan.Discriminator().to(device)\n",
    "optimD = torch.optim.Adam(netD.parameters(), lr=params['lrd'], betas=(params['beta1'], params['beta2']))\n",
    "netG.load_state_dict(torch.load('../../model/aot-model_colon/generator_62.pt',map_location=device))\n",
    "netD.load_state_dict(torch.load('../../model/aot-model_colon/discriminator_62.pt',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(netG, input_size=((params['batch_size'], 3, params['image_size'], params['image_size']),(params['batch_size'], 1, params['image_size'], params['image_size'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='../../data/dataset/colon/test/result/'\n",
    "with torch.no_grad():\n",
    "    test=tqdm(test_dataloader)\n",
    "    count=0\n",
    "    for images, masks,filename in test:\n",
    "        count+=1\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        images_masked = (images * (1 - masks).float()) + masks\n",
    "        pred_img = netG(images_masked, masks)\n",
    "        comp_img = (1 - masks) * images + masks * pred_img\n",
    "        for i in range(params['batch_size']):\n",
    "            img3=np.transpose((pred_img[i].cpu().detach().numpy()/2+0.5)*255,(1,2,0))\n",
    "            pillow_pred=Image.fromarray(img3.astype(np.uint8))\n",
    "            pillow_pred.save(save_path+filename[i])\n",
    "        ax=plt.figure(figsize=(24,8))\n",
    "        ax.add_subplot(1,3,1)\n",
    "        plt.imshow(np.transpose(images[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,2)\n",
    "        plt.imshow(np.transpose(images_masked[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        ax.add_subplot(1,3,3)\n",
    "        plt.imshow(np.transpose(pred_img[0].cpu().detach().numpy(),(1,2,0))/2+0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=np.transpose((images[0].cpu().detach().numpy()/2+0.5)*255,(1,2,0))\n",
    "img2=np.transpose((masks[0].cpu().detach().numpy())*255,(1,2,0))\n",
    "img3=np.transpose((pred_img[0].cpu().detach().numpy()/2+0.5)*255,(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_mask=Image.fromarray(img2[:,:,0].astype(np.uint8))\n",
    "pillow_image=Image.fromarray(img1.astype(np.uint8))\n",
    "pillow_pred=Image.fromarray(img3.astype(np.uint8))\n",
    "pillow_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
